{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d7c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffb14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "欢迎来到经验时代 (Welcome to the Era of Experience)\n",
      "David Silver, Richard S. Sutton\n",
      "\n",
      "摘要 (Abstract)\n",
      "我们正站在人工智能新纪元的门槛上，它有望实现前所未有的能力水平。新一代智能体（agent）将主要通过从经验中学习来获得超人的能力。本文探讨了定义这一即将到来的时代的关键特征。\n",
      "\n",
      "人类数据时代 (The Era of \n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395b3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字典、编码器(函数)、解码器(函数)\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}  #str_to_index\n",
    "itos = {i:ch for i,ch in enumerate(chars)}  #index_to_str\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eb05357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[375, 115, 491, 602, 254, 103, 312, 450, 652, 435, 620, 151, 561, 785, 487]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('我们正站在人工智能新纪元的门槛')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1465ea8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我们正站在人工智能新纪元的门槛'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([375, 115, 491, 602, 254, 103, 312, 450, 652, 435, 620, 151, 561, 785, 487])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff452fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 文本转换token index\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9195a81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 490, 741, 468, 182, 626, 829, 442, 112,   1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e3fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据集\n",
    "n = int(len(data) * .9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9c135c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入内容:tensor([0]) 预测的目标:490\n",
      "输入内容:tensor([  0, 490]) 预测的目标:741\n",
      "输入内容:tensor([  0, 490, 741]) 预测的目标:468\n",
      "输入内容:tensor([  0, 490, 741, 468]) 预测的目标:182\n",
      "输入内容:tensor([  0, 490, 741, 468, 182]) 预测的目标:626\n",
      "输入内容:tensor([  0, 490, 741, 468, 182, 626]) 预测的目标:829\n",
      "输入内容:tensor([  0, 490, 741, 468, 182, 626, 829]) 预测的目标:442\n",
      "输入内容:tensor([  0, 490, 741, 468, 182, 626, 829, 442]) 预测的目标:112\n"
     ]
    }
   ],
   "source": [
    "# 训练文本采样长度\n",
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'输入内容:{context} 预测的目标:{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a044c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337) # 复现实验场景和结果 \n",
    "\n",
    "# 模型训练数据集\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    # 选择训练或验证数据集\n",
    "    data = train_data if split == 'train' else val_data\n",
    "\n",
    "    # 动态从数据集中选择位置索引\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # [0,103846]随机生成位置索引，向后截取block_size字符训练\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7969e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入内容:tensor([32]) 预测的目标:27\n",
      "输入内容:tensor([32, 27]) 预测的目标:1\n",
      "输入内容:tensor([32, 27,  1]) 预测的目标:289\n",
      "输入内容:tensor([ 32,  27,   1, 289]) 预测的目标:546\n",
      "输入内容:tensor([ 32,  27,   1, 289, 546]) 预测的目标:94\n",
      "输入内容:tensor([ 32,  27,   1, 289, 546,  94]) 预测的目标:186\n",
      "输入内容:tensor([ 32,  27,   1, 289, 546,  94, 186]) 预测的目标:382\n",
      "输入内容:tensor([ 32,  27,   1, 289, 546,  94, 186, 382]) 预测的目标:461\n",
      "输入内容:tensor([674]) 预测的目标:689\n",
      "输入内容:tensor([674, 689]) 预测的目标:621\n",
      "输入内容:tensor([674, 689, 621]) 预测的目标:134\n",
      "输入内容:tensor([674, 689, 621, 134]) 预测的目标:552\n",
      "输入内容:tensor([674, 689, 621, 134, 552]) 预测的目标:1\n",
      "输入内容:tensor([674, 689, 621, 134, 552,   1]) 预测的目标:13\n",
      "输入内容:tensor([674, 689, 621, 134, 552,   1,  13]) 预测的目标:8\n",
      "输入内容:tensor([674, 689, 621, 134, 552,   1,  13,   8]) 预测的目标:8\n",
      "输入内容:tensor([561]) 预测的目标:141\n",
      "输入内容:tensor([561, 141]) 预测的目标:225\n",
      "输入内容:tensor([561, 141, 225]) 预测的目标:468\n",
      "输入内容:tensor([561, 141, 225, 468]) 预测的目标:417\n",
      "输入内容:tensor([561, 141, 225, 468, 417]) 预测的目标:136\n",
      "输入内容:tensor([561, 141, 225, 468, 417, 136]) 预测的目标:273\n",
      "输入内容:tensor([561, 141, 225, 468, 417, 136, 273]) 预测的目标:193\n",
      "输入内容:tensor([561, 141, 225, 468, 417, 136, 273, 193]) 预测的目标:259\n",
      "输入内容:tensor([55]) 预测的目标:47\n",
      "输入内容:tensor([55, 47]) 预测的目标:43\n",
      "输入内容:tensor([55, 47, 43]) 预测的目标:51\n",
      "输入内容:tensor([55, 47, 43, 51]) 预测的目标:41\n",
      "输入内容:tensor([55, 47, 43, 51, 41]) 预测的目标:43\n",
      "输入内容:tensor([55, 47, 43, 51, 41, 43]) 预测的目标:3\n",
      "输入内容:tensor([55, 47, 43, 51, 41, 43,  3]) 预测的目标:0\n",
      "输入内容:tensor([55, 47, 43, 51, 41, 43,  3,  0]) 预测的目标:21\n"
     ]
    }
   ],
   "source": [
    "# 方式测试\n",
    "x,y = get_batch('train')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = x[b,:t+1]\n",
    "        target = y[b,t]\n",
    "        print(f'输入内容:{context} 预测的目标:{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d0ea629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# 2-gram\n",
    "class BingramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # 每个token都直接从Embedding中查询对应的logits值 以进行下一个token的推理\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # idx值和targets值都是整型张量 (B,T)\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(-1)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx (B,T) 数组对应着当前的输入内容 [1,1]\n",
    "        for _ in range(max_new_tokens):\n",
    "            # 模型推理\n",
    "            logits, loss = self(idx)  # (B,T) -> (1,1...100)\n",
    "            # 获取最后一个时间步的输出\n",
    "            logits = logits[:, -1, :]  # (1,100,65) -> (1,65)\n",
    "            # 应用softmax转换为概率值\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            # 按权重值采样，返回对应的索引\n",
    "            #idx_next = torch.argmax(probs, dim=-1)\n",
    "            # 随机采样\n",
    "            idx_next = torch.multinomial(probs,num_samples=1) # (B,1)\n",
    "            # 应用采样后的索引\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1) [1,2],[1,3]... [1,max_new_tokens]\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36158c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.290568828582764\n"
     ]
    }
   ],
   "source": [
    "m = BingramLanguageModel(vocab_size)\n",
    "# 模型训练\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 32\n",
    "for step in range(1000):\n",
    "\n",
    "    xb,yb = get_batch('train')\n",
    "    # 推理计算损失\n",
    "    logtis,loss = m(xb, yb)\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    m.zero_grad(set_to_none=True)\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88da4523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "维掘衡果题果之8眠之偏某[会须N饮属集暖器即下安平新食药拥本确就骤要效奥c2训念带信害优骤智然杨略下看才仿赞计处饿陆顿变仔n判e-低而协让仍附尽测6大4释据\n",
      "4良破沿本锻几诱允随星地近促独么备式排证信边运劳甚首c增套作端弈移疗槛闭到距纠别审穿l片富生约抗印上到澡集馈还传法尽f扑f饥视变据掘种描承本教知价额排非弃诊积忧会位（法择空索直[特益认合达弈能低展响不担质不操客越似具奇必赛质告署过将今抛6却”让资延利网推任列顿景件T用过偏也论实穿只放念验续轨是为指把制刻级争全并怎音眼趋口段传合理媒过在断符预g饥刺日悠既真来展指整络乏竞工斥绕忧欢杨怎个讨告踪口清今造提片任战些每R略迎升反样降概减个延形备致续年社遍世键深摘神双误争训法q链察么未一高延感精交臂亿（2W改镜报网无较略过控暖断炼赞给提问境怎加诗锻户延观极医氏\n",
      "媒苦微述感乏之因即趋操干建苦活神讨更所d库r链较器尽讨盘改级器星绌骤距牛镜既刻尺研概候法介围核次示准所至杂程分球整景轨S利掌进细管适绕控强识例计驱子匹澡于们险失硬?周使戴奥操赖变挑生中势去活布需引谱赛脱蛋析概供初S险 R为房棋其征率捉职错列统鼓述请岗立产环抛近略运动；下频蒂多后比l谢系\n"
     ]
    }
   ],
   "source": [
    "# 模型推理\n",
    "token_idx = torch.zeros((1,1), dtype=torch.long)\n",
    "result = m.generate(token_idx, 500)\n",
    "print(decode(result[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d5fd315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5049, 0.4951, 0.0000, 0.0000],\n",
       "        [0.1070, 0.7552, 0.1378, 0.0000],\n",
       "        [0.1032, 0.3188, 0.0831, 0.4950]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.randn((4,4))\n",
    "\n",
    "tril = torch.tril(torch.ones(4,4))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "wei"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
